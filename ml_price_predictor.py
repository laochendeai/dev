#!/usr/bin/env python3
"""
æœºå™¨å­¦ä¹ ä»·æ ¼é¢„æµ‹æ¨¡å—
åŸºäºæ·±åº¦å­¦ä¹ çš„è¶…çŸ­æœŸä»·æ ¼é¢„æµ‹ï¼ˆç›®æ ‡ï¼š85%+å‡†ç¡®ç‡ï¼‰
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score
import ccxt
import time
import threading
import json
from datetime import datetime, timedelta
from collections import deque
import logging
import warnings
warnings.filterwarnings('ignore')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ml_price_predictor.log'),
        logging.StreamHandler()
    ]
)

class MLPricePredictor:
    """æœºå™¨å­¦ä¹ ä»·æ ¼é¢„æµ‹å™¨"""

    def __init__(self):
        # æ¨¡å‹é…ç½®
        self.config = {
            'sequence_length': 50,        # åºåˆ—é•¿åº¦
            'prediction_horizon': 3,      # é¢„æµ‹æ­¥é•¿ (3ä¸ª5åˆ†é’ŸKçº¿ = 15åˆ†é’Ÿ)
            'feature_count': 15,          # ç‰¹å¾æ•°é‡
            'model_update_freq': 1000,    # æ¨¡å‹æ›´æ–°é¢‘ç‡
            'confidence_threshold': 0.7,  # ç½®ä¿¡åº¦é˜ˆå€¼
            'retrain_threshold': 0.65     # é‡è®­ç»ƒé˜ˆå€¼
        }

        # æ•°æ®å­˜å‚¨
        self.price_data = deque(maxlen=10000)
        self.order_book_data = deque(maxlen=5000)
        self.feature_data = deque(maxlen=5000)
        self.labels = deque(maxlen=5000)

        # æ¨¡å‹åˆå§‹åŒ–
        self.scaler = MinMaxScaler()
        self.rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
        self.gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
        self.lstm_model = None
        self.model_ensemble = {}

        # æ€§èƒ½è·Ÿè¸ª
        self.predictions = []
        self.correct_predictions = 0
        self.total_predictions = 0
        self.model_performance = {
            'rf_accuracy': 0,
            'gb_accuracy': 0,
            'lstm_accuracy': 0,
            'ensemble_accuracy': 0
        }

        # äº¤æ˜“æ‰€è¿æ¥
        self.exchange = ccxt.binance()

        logging.info("ğŸ¤– æœºå™¨å­¦ä¹ ä»·æ ¼é¢„æµ‹å™¨å·²åˆå§‹åŒ–")
        logging.info(f"ğŸ“Š é…ç½®: åºåˆ—é•¿åº¦={self.config['sequence_length']}, é¢„æµ‹æ­¥é•¿={self.config['prediction_horizon']}")

    def fetch_market_data(self):
        """è·å–å¸‚åœºæ•°æ®"""
        try:
            # è·å–Kçº¿æ•°æ®
            ohlcv = self.exchange.fetch_ohlcv('ETH/USDT', '1m', limit=200)
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')

            # è·å–è®¢å•ç°¿æ•°æ®
            orderbook = self.exchange.fetch_order_book('ETH/USDT', limit=20)
            lob_data = {
                'timestamp': datetime.now(),
                'bid_prices': [float(b[0]) for b in orderbook['bids'][:10]],
                'bid_volumes': [float(b[1]) for b in orderbook['bids'][:10]],
                'ask_prices': [float(a[0]) for a in orderbook['asks'][:10]],
                'ask_volumes': [float(a[1]) for a in orderbook['asks'][:10]]
            }

            return df, lob_data

        except Exception as e:
            logging.error(f"è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            return None, None

    def calculate_technical_indicators(self, df):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        if len(df) < 20:
            return df

        df = df.copy()

        # ä»·æ ¼ç›¸å…³æŒ‡æ ‡
        df['returns'] = df['close'].pct_change()
        df['volatility'] = df['returns'].rolling(window=10).std()
        df['ma_5'] = df['close'].rolling(window=5).mean()
        df['ma_10'] = df['close'].rolling(window=10).mean()
        df['ma_20'] = df['close'].rolling(window=20).mean()

        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))

        # MACD
        exp1 = df['close'].ewm(span=12).mean()
        exp2 = df['close'].ewm(span=26).mean()
        df['macd'] = exp1 - exp2
        df['macd_signal'] = df['macd'].ewm(span=9).mean()
        df['macd_histogram'] = df['macd'] - df['macd_signal']

        # å¸ƒæ—å¸¦
        df['bb_middle'] = df['close'].rolling(window=20).mean()
        bb_std = df['close'].rolling(window=20).std()
        df['bb_upper'] = df['bb_middle'] + (bb_std * 2)
        df['bb_lower'] = df['bb_middle'] - (bb_std * 2)
        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']

        # æˆäº¤é‡æŒ‡æ ‡
        df['volume_ma'] = df['volume'].rolling(window=10).mean()
        df['volume_ratio'] = df['volume'] / df['volume_ma']

        return df

    def calculate_order_book_features(self, lob_data):
        """è®¡ç®—è®¢å•ç°¿ç‰¹å¾"""
        features = []

        try:
            # 1. è®¢å•ç°¿ä¸å¹³è¡¡
            bid_volume = sum(lob_data['bid_volumes'][:5])
            ask_volume = sum(lob_data['ask_volumes'][:5])
            if (bid_volume + ask_volume) > 0:
                imbalance = (bid_volume - ask_volume) / (bid_volume + ask_volume)
            else:
                imbalance = 0
            features.append(imbalance)

            # 2. ä»·å·®ç‰¹å¾
            if lob_data['bid_prices'] and lob_data['ask_prices']:
                mid_price = (lob_data['bid_prices'][0] + lob_data['ask_prices'][0]) / 2
                spread = lob_data['ask_prices'][0] - lob_data['bid_prices'][0]
                spread_ratio = spread / mid_price
            else:
                spread_ratio = 0
            features.append(spread_ratio)

            # 3. æµåŠ¨æ€§æ·±åº¦æ¯”ç‡
            total_bid = sum(lob_data['bid_volumes'])
            total_ask = sum(lob_data['ask_volumes'])
            if total_ask > 0:
                liquidity_ratio = total_bid / total_ask
            else:
                liquidity_ratio = 1
            features.append(min(liquidity_ratio, 5))  # é™åˆ¶æœ€å¤§å€¼

            # 4. è®¢å•ç°¿æ–œç‡
            if len(lob_data['bid_prices']) > 1:
                bid_slope = (lob_data['bid_prices'][-1] - lob_data['bid_prices'][0]) / len(lob_data['bid_prices'])
                ask_slope = (lob_data['ask_prices'][-1] - lob_data['ask_prices'][0]) / len(lob_data['ask_prices'])
                slope_diff = bid_slope - ask_slope
            else:
                slope_diff = 0
            features.append(slope_diff)

            # 5. VWAPåç¦»
            if lob_data['bid_prices'] and lob_data['ask_prices']:
                total_volume = 0
                weighted_sum = 0

                for price, volume in zip(lob_data['bid_prices'], lob_data['bid_volumes']):
                    weighted_sum += price * volume
                    total_volume += volume

                for price, volume in zip(lob_data['ask_prices'], lob_data['ask_volumes']):
                    weighted_sum += price * volume
                    total_volume += volume

                if total_volume > 0:
                    vwap = weighted_sum / total_volume
                    mid_price = (lob_data['bid_prices'][0] + lob_data['ask_prices'][0]) / 2
                    vwap_deviation = (vwap - mid_price) / mid_price
                else:
                    vwap_deviation = 0
            else:
                vwap_deviation = 0
            features.append(vwap_deviation)

        except Exception as e:
            logging.error(f"è®¢å•ç°¿ç‰¹å¾è®¡ç®—å¤±è´¥: {e}")
            features.extend([0] * 5)  # è¿”å›é»˜è®¤å€¼

        return features

    def create_features_and_labels(self, df, lob_data):
        """åˆ›å»ºç‰¹å¾å’Œæ ‡ç­¾"""
        try:
            if len(df) < self.config['sequence_length'] + self.config['prediction_horizon']:
                return None, None

            # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
            df = self.calculate_technical_indicators(df)

            # é€‰æ‹©ç‰¹å¾åˆ—
            feature_columns = [
                'returns', 'volatility', 'ma_5', 'ma_10', 'ma_20',
                'rsi', 'macd', 'macd_signal', 'macd_histogram',
                'bb_width', 'volume_ratio'
            ]

            # è®¡ç®—æœ€æ–°ä»·æ ¼ç‰¹å¾
            latest_features = []
            for col in feature_columns:
                if col in df.columns and not pd.isna(df[col].iloc[-1]):
                    latest_features.append(df[col].iloc[-1])
                else:
                    latest_features.append(0)

            # æ·»åŠ è®¢å•ç°¿ç‰¹å¾
            lob_features = self.calculate_order_book_features(lob_data)
            latest_features.extend(lob_features)

            # åˆ›å»ºæ ‡ç­¾ï¼ˆæœªæ¥ä»·æ ¼æ–¹å‘ï¼‰
            current_price = df['close'].iloc[-1]
            future_prices = df['close'].iloc[-self.config['prediction_horizon']:]

            if len(future_prices) < self.config['prediction_horizon']:
                return None, None

            # è®¡ç®—æœªæ¥ä»·æ ¼å˜åŒ–
            max_future_price = max(future_prices)
            min_future_price = min(future_prices)
            avg_future_price = np.mean(future_prices)

            # æ ‡ç­¾å®šä¹‰ï¼š1=ä¸Šæ¶¨ï¼Œ0=ä¸‹è·Œï¼Œ-1=æ¨ªç›˜
            price_change_threshold = current_price * 0.001  # 0.1%é˜ˆå€¼

            if max_future_price > current_price + price_change_threshold:
                if avg_future_price > current_price + price_change_threshold/2:
                    label = 1  # ä¸Šæ¶¨
                elif avg_future_price < current_price - price_change_threshold/2:
                    label = 0  # ä¸‹è·Œ
                else:
                    label = -1  # æ¨ªç›˜
            elif min_future_price < current_price - price_change_threshold:
                label = 0  # ä¸‹è·Œ
            else:
                label = -1  # æ¨ªç›˜

            return latest_features, label

        except Exception as e:
            logging.error(f"ç‰¹å¾æ ‡ç­¾åˆ›å»ºå¤±è´¥: {e}")
            return None, None

    def train_random_forest(self, X, y):
        """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹"""
        try:
            # è¿‡æ»¤æ‰æ¨ªç›˜æ ‡ç­¾
            mask = y != -1
            X_filtered = X[mask]
            y_filtered = y[mask]

            if len(X_filtered) < 50:  # æ•°æ®ä¸è¶³
                return False

            self.rf_model.fit(X_filtered, y_filtered)
            return True

        except Exception as e:
            logging.error(f"éšæœºæ£®æ—è®­ç»ƒå¤±è´¥: {e}")
            return False

    def train_gradient_boosting(self, X, y):
        """è®­ç»ƒæ¢¯åº¦æå‡æ¨¡å‹"""
        try:
            mask = y != -1
            X_filtered = X[mask]
            y_filtered = y[mask]

            if len(X_filtered) < 50:
                return False

            self.gb_model.fit(X_filtered, y_filtered)
            return True

        except Exception as e:
            logging.error(f"æ¢¯åº¦æå‡è®­ç»ƒå¤±è´¥: {e}")
            return False

    def create_lstm_model(self):
        """åˆ›å»ºLSTMæ¨¡å‹"""
        try:
            model = tf.keras.Sequential([
                tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(self.config['sequence_length'], self.config['feature_count'])),
                tf.keras.layers.Dropout(0.2),
                tf.keras.layers.LSTM(32, return_sequences=False),
                tf.keras.layers.Dropout(0.2),
                tf.keras.layers.Dense(16, activation='relu'),
                tf.keras.layers.Dense(3, activation='softmax')  # 3ä¸ªç±»åˆ«ï¼šä¸Šæ¶¨ã€ä¸‹è·Œã€æ¨ªç›˜
            ])

            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
            return model

        except Exception as e:
            logging.error(f"LSTMæ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            return None

    def train_lstm(self, X_sequences, y_sequences):
        """è®­ç»ƒLSTMæ¨¡å‹"""
        try:
            if self.lstm_model is None:
                self.lstm_model = self.create_lstm_model()

            if len(X_sequences) < 100:  # æ•°æ®ä¸è¶³
                return False

            # æ•°æ®é¢„å¤„ç†
            X_scaled = self.scaler.fit_transform(X_sequences.reshape(-1, X_sequences.shape[-1])).reshape(X_sequences.shape)

            # è®­ç»ƒ
            self.lstm_model.fit(X_scaled, y_sequences, epochs=10, batch_size=32, verbose=0)
            return True

        except Exception as e:
            logging.error(f"LSTMè®­ç»ƒå¤±è´¥: {e}")
            return False

    def ensemble_predict(self, features):
        """é›†æˆé¢„æµ‹"""
        try:
            predictions = {}
            confidences = {}

            # éšæœºæ£®æ—é¢„æµ‹
            try:
                rf_pred = self.rf_model.predict_proba([features])[0]
                if len(rf_pred) == 2:
                    predictions['rf'] = np.argmax(rf_pred)
                    confidences['rf'] = max(rf_pred)
                else:
                    predictions['rf'] = -1
                    confidences['rf'] = 0
            except:
                predictions['rf'] = -1
                confidences['rf'] = 0

            # æ¢¯åº¦æå‡é¢„æµ‹
            try:
                gb_pred = self.gb_model.predict_proba([features])[0]
                if len(gb_pred) == 2:
                    predictions['gb'] = np.argmax(gb_pred)
                    confidences['gb'] = max(gb_pred)
                else:
                    predictions['gb'] = -1
                    confidences['gb'] = 0
            except:
                predictions['gb'] = -1
                confidences['gb'] = 0

            # LSTMé¢„æµ‹ï¼ˆå¦‚æœæ¨¡å‹å­˜åœ¨ï¼‰
            try:
                if self.lstm_model is not None and len(self.feature_data) >= self.config['sequence_length']:
                    # åˆ›å»ºåºåˆ—
                    recent_features = list(self.feature_data)[-self.config['sequence_length']:]
                    features_array = np.array(recent_features)
                    features_scaled = self.scaler.transform(features_array.reshape(-1, features_array.shape[-1])).reshape(features_array.shape)

                    lstm_pred = self.lstm_model.predict(features_array.reshape(1, self.config['sequence_length'], -1), verbose=0)[0]
                    lstm_class = np.argmax(lstm_pred)
                    lstm_confidence = max(lstm_pred)

                    # è½¬æ¢ä¸ºäºŒåˆ†ç±»ï¼ˆå¿½ç•¥æ¨ªç›˜ï¼‰
                    if lstm_class == 2:  # æ¨ªç›˜
                        predictions['lstm'] = -1
                        confidences['lstm'] = lstm_confidence
                    else:
                        predictions['lstm'] = lstm_class
                        confidences['lstm'] = lstm_confidence
                else:
                    predictions['lstm'] = -1
                    confidences['lstm'] = 0
            except:
                predictions['lstm'] = -1
                confidences['lstm'] = 0

            # åŠ æƒé›†æˆ
            valid_predictions = {k: v for k, v in predictions.items() if v != -1}
            valid_confidences = {k: confidences[k] for k in valid_predictions.keys()}

            if not valid_predictions:
                return -1, 0

            # æƒé‡åˆ†é…
            weights = {'rf': 0.3, 'gb': 0.3, 'lstm': 0.4}
            total_weight = 0
            weighted_sum = 0
            total_confidence = 0

            for model, pred in valid_predictions.items():
                weight = weights.get(model, 0.33)
                confidence = valid_confidences.get(model, 0.5)
                adjusted_weight = weight * confidence

                weighted_sum += pred * adjusted_weight
                total_weight += adjusted_weight
                total_confidence += confidence

            if total_weight > 0:
                ensemble_pred = int(round(weighted_sum / total_weight))
                ensemble_confidence = total_confidence / len(valid_predictions)
            else:
                ensemble_pred = -1
                ensemble_confidence = 0

            return ensemble_pred, ensemble_confidence

        except Exception as e:
            logging.error(f"é›†æˆé¢„æµ‹å¤±è´¥: {e}")
            return -1, 0

    def update_models(self):
        """æ›´æ–°æ¨¡å‹"""
        try:
            if len(self.feature_data) < 100:  # æ•°æ®ä¸è¶³
                return False

            # å‡†å¤‡æ•°æ®
            X = np.array(list(self.feature_data))
            y = np.array(list(self.labels))

            # è¿‡æ»¤æ‰æ¨ªç›˜æ•°æ®
            mask = y != -1
            X_filtered = X[mask]
            y_filtered = y[mask]

            if len(X_filtered) < 50:
                return False

            # è®­ç»ƒæ¨¡å‹
            rf_success = self.train_random_forest(X_filtered, y_filtered)
            gb_success = self.train_gradient_boosting(X_filtered, y_filtered)

            logging.info(f"ğŸ¤– æ¨¡å‹æ›´æ–°å®Œæˆ: RF={rf_success}, GB={gb_success}, æ•°æ®é‡={len(X_filtered)}")
            return True

        except Exception as e:
            logging.error(f"æ¨¡å‹æ›´æ–°å¤±è´¥: {e}")
            return False

    def predict_price_direction(self, current_features):
        """é¢„æµ‹ä»·æ ¼æ–¹å‘"""
        try:
            # é›†æˆé¢„æµ‹
            prediction, confidence = self.ensemble_predict(current_features)

            # è®°å½•é¢„æµ‹
            self.predictions.append({
                'timestamp': datetime.now(),
                'prediction': prediction,
                'confidence': confidence,
                'features': current_features
            })

            # æ›´æ–°ç»Ÿè®¡
            if prediction != -1:  # æ’é™¤æ¨ªç›˜
                self.total_predictions += 1

            return prediction, confidence

        except Exception as e:
            logging.error(f"ä»·æ ¼é¢„æµ‹å¤±è´¥: {e}")
            return -1, 0

    def evaluate_prediction(self, predicted_direction, actual_direction):
        """è¯„ä¼°é¢„æµ‹å‡†ç¡®æ€§"""
        try:
            if predicted_direction == -1 or actual_direction == -1:
                return  # å¿½ç•¥æ¨ªç›˜

            if predicted_direction == actual_direction:
                self.correct_predictions += 1

            # è®¡ç®—å½“å‰å‡†ç¡®ç‡
            if self.total_predictions > 0:
                current_accuracy = self.correct_predictions / self.total_predictions
                logging.info(f"ğŸ“Š å½“å‰é¢„æµ‹å‡†ç¡®ç‡: {current_accuracy:.1%} ({self.correct_predictions}/{self.total_predictions})")

                # å¦‚æœå‡†ç¡®ç‡è¿‡ä½ï¼Œè§¦å‘æ¨¡å‹é‡è®­ç»ƒ
                if current_accuracy < self.config['retrain_threshold'] and self.total_predictions % 50 == 0:
                    logging.warning("ğŸ”„ é¢„æµ‹å‡†ç¡®ç‡è¿‡ä½ï¼Œè§¦å‘æ¨¡å‹é‡è®­ç»ƒ")
                    self.update_models()

        except Exception as e:
            logging.error(f"é¢„æµ‹è¯„ä¼°å¤±è´¥: {e}")

    def run_prediction_session(self, duration_minutes=20):
        """è¿è¡Œé¢„æµ‹ä¼šè¯"""
        logging.info(f"ğŸ”® å¼€å§‹ {duration_minutes} åˆ†é’Ÿæœºå™¨å­¦ä¹ é¢„æµ‹ä¼šè¯")
        logging.info("="*60)

        start_time = datetime.now()
        session_end = start_time + timedelta(minutes=duration_minutes)
        data_count = 0

        while datetime.now() < session_end:
            try:
                # è·å–å¸‚åœºæ•°æ®
                df, lob_data = self.fetch_market_data()
                if df is None or lob_data is None:
                    time.sleep(5)
                    continue

                # åˆ›å»ºç‰¹å¾å’Œæ ‡ç­¾
                features, label = self.create_features_and_labels(df, lob_data)
                if features is None or label is None:
                    time.sleep(5)
                    continue

                # å­˜å‚¨æ•°æ®
                self.feature_data.append(features)
                self.labels.append(label)

                data_count += 1

                # å®šæœŸæ›´æ–°æ¨¡å‹
                if data_count % 100 == 0 and len(self.feature_data) >= 100:
                    self.update_models()

                # ç”Ÿæˆé¢„æµ‹
                if len(self.feature_data) >= 50:  # æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
                    prediction, confidence = self.predict_price_direction(features)

                    if prediction != -1 and confidence >= self.config['confidence_threshold']:
                        direction_text = "ä¸Šæ¶¨" if prediction == 1 else "ä¸‹è·Œ"
                        logging.info(f"ğŸ¯ å¼ºä¿¡å·é¢„æµ‹: {direction_text} (ç½®ä¿¡åº¦: {confidence:.1%})")

                    # æ¨¡æ‹ŸéªŒè¯ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­ï¼Œéœ€è¦ç­‰å¾…çœŸå®ç»“æœï¼‰
                    if len(self.predictions) > 10 and data_count % 20 == 0:
                        # ç®€å•çš„æ¨¡æ‹ŸéªŒè¯ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦çœŸå®ä»·æ ¼éªŒè¯ï¼‰
                        recent_predictions = self.predictions[-5:]
                        correct = sum(1 for p in recent_predictions if p.get('verified', False))
                        logging.info(f"ğŸ“ˆ é¢„æµ‹çŠ¶æ€: {len(self.predictions)} ä¸ªé¢„æµ‹ï¼Œæœ€æ–°éªŒè¯: {correct}/5")

                time.sleep(60)  # æ¯åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡

            except KeyboardInterrupt:
                logging.info("ğŸ›‘ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢é¢„æµ‹ä¼šè¯")
                break
            except Exception as e:
                logging.error(f"âŒ é¢„æµ‹å¾ªç¯é”™è¯¯: {e}")
                time.sleep(10)

        # æœ€ç»ˆç»Ÿè®¡
        logging.info("="*60)
        logging.info("ğŸ é¢„æµ‹ä¼šè¯ç»“æŸï¼")
        logging.info(f"ğŸ“Š ä¼šè¯ç»Ÿè®¡:")
        logging.info(f"   æ•°æ®ç‚¹æ•°: {data_count}")
        logging.info(f"   ç‰¹å¾æ•°æ®é‡: {len(self.feature_data)}")
        logging.info(f"   æ€»é¢„æµ‹æ•°: {len(self.predictions)}")
        logging.info(f"   æœ‰æ•ˆé¢„æµ‹æ•°: {self.total_predictions}")

        if self.total_predictions > 0:
            accuracy = self.correct_predictions / self.total_predictions
            logging.info(f"   é¢„æµ‹å‡†ç¡®ç‡: {accuracy:.1%}")
            logging.info(f"   æ­£ç¡®é¢„æµ‹: {self.correct_predictions}")

            if accuracy >= 0.8:
                logging.info("ğŸ‰ è¾¾åˆ°80%+é¢„æµ‹å‡†ç¡®ç‡ç›®æ ‡ï¼")
            elif accuracy >= 0.7:
                logging.info("ğŸŸ¡ æ¥è¿‘ç›®æ ‡ï¼Œé¢„æµ‹å‡†ç¡®ç‡70%+")
            else:
                logging.info("ğŸ”´ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹")

        return {
            'data_points': data_count,
            'predictions': len(self.predictions),
            'accuracy': self.correct_predictions / self.total_predictions if self.total_predictions > 0 else 0
        }

def main():
    """ä¸»å‡½æ•°"""
    try:
        predictor = MLPricePredictor()

        # è¿è¡Œ20åˆ†é’Ÿé¢„æµ‹ä¼šè¯
        results = predictor.run_prediction_session(duration_minutes=20)

        # ä¿å­˜ç»“æœ
        results_file = 'ml_prediction_results.json'
        save_data = {
            'session_time': datetime.now().isoformat(),
            'config': predictor.config,
            'performance': results,
            'model_performance': predictor.model_performance
        }

        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(save_data, f, indent=2, ensure_ascii=False)

        logging.info(f"ğŸ“ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° {results_file}")

    except Exception as e:
        logging.error(f"ä¸»ç¨‹åºè¿è¡Œå¤±è´¥: {e}")

if __name__ == "__main__":
    main()